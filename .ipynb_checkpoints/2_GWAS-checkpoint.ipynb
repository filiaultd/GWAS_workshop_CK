{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GWAS using limix\n",
    "We're going to run GWAS using the limix library for python.\n",
    "Limix is freely available [here](https://github.com/limix/limix) and has an extensive [documentation](https://limix.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Initial setup steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from limix.qtl import scan\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenotypes\n",
    "pheno_file = './data/subset_flowering_time_16.csv'\n",
    "# genotypes\n",
    "#geno_file = './data/all_chromosomes_binary.hdf5'\n",
    "geno_file = './data/subset_all_chromosomes_binary.hdf5'\n",
    "# kinship matrix\n",
    "kin_file = './data/kinship_ibs_binary_mac5.h5py'\n",
    "# minor allele frequency threshold\n",
    "MAF_thrs = 0.1\n",
    "# output results\n",
    "output_file = './data/subset_flowering_time_16_gwas.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing input for GWAS\n",
    "We need three variables to run GWAS:\n",
    "1.  Phenotype matrix (Y)\n",
    "2.  Genotype matrix (G)\n",
    "3.  K matrix (K)\n",
    "\n",
    "Let's prepare these one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Load phenotypes\n",
    "The phenotype data are stored in a 2-column .csv file.\n",
    "The first column specifies the accession identifier, the second column contains the phenotype value.  For flowering time, there are 200 accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenotype data\n",
    "pheno = pd.read_csv(pheno_file, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "           flowering_time_16\n",
      "ecotypeid                   \n",
      "b'770'                 72.25\n",
      "b'801'                 88.25\n",
      "b'991'                106.75\n",
      "b'1062'                68.25\n",
      "b'1367'                88.75\n"
     ]
    }
   ],
   "source": [
    "# remove NA values\n",
    "pheno = pheno[np.isfinite(pheno)]\n",
    "# encode the index to UTF8 for compatability with the genotype data\n",
    "pheno.index = pheno.index.map(lambda x: str(int(x)).encode('UTF8'))\n",
    "# does pheno match our expectations?\n",
    "print(pheno.shape)\n",
    "print(pheno.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenotypes are loaded.  However, since all accessions in the phenotype matrix __*also*__ need to be in the genotype matrix, we need to load the genotypes before we can finalize the phenotype matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Load genotypes\n",
    "The genotypes we're going to use are a subset of SNPs obtained from whole genome resequencing of 1,135 *Arabidopsis thaliana* accessions ([1001 genomes](http://1001genomes.org/)).\n",
    "Genotype data is stored as an [hdf5](https://www.h5py.org/) file, which is a composite data type.  The genotype file we are using here consists of three data sets.  The first ('accessions') contains the accession identifiers.  The second ('positions') provides the SNP positions.  The third ('snps') gives the SNP calls themselves, with SNPs coded as 0 or 1.  The 'positions' dataset also has two associated attributes which provide information about the chromosome location ('chr' and 'chr_index') which we will use later when outputting GWAS results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accessions\n",
      "(1135,)\n",
      "[b'88' b'108' b'139' b'159' b'265']\n",
      "positions\n",
      "(1070995,)\n",
      "[ 55 101 139 203 237]\n",
      "snps\n",
      "(1070995, 1135)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# load genotype data\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "# does geno_hdf match our expectations?\n",
    "for key in geno_hdf.keys():\n",
    "    print(key)\n",
    "    print(geno_hdf[key].shape)\n",
    "    print(geno_hdf[key][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c.  Finish phenotype matrix (Y)\n",
    "\n",
    "We now have the phenotypes stored as the variable called pheno.  To finish the phenotype matrix (Y), we need to remove non-genotyped accessions and order the data to match the genotype data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-genotyped accessions from phenotype\n",
    "acn_genotyped = [acn for acn in pheno.index if acn in geno_hdf['accessions'][:]]\n",
    "# subset phenotype data\n",
    "pheno = pheno.loc[acn_genotyped]\n",
    "# order genotypes in phenotype according SNP-matrix\n",
    "acn_indices = [np.where(geno_hdf['accessions'][:] == acn)[0][0] for acn in pheno.index]\n",
    "acn_indices.sort()\n",
    "acn_order = geno_hdf['accessions'][acn_indices]\n",
    "pheno = pheno.loc[acn_order]\n",
    "# transform to phenotype matrix (Y)\n",
    "Y = pheno.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d. Finish genotype matrix (G)\n",
    "The phenotype matrix is ready to go.  Now we can finish the genotype matrix (G).  Here we remove accessions that are not genotyped and SNPs with a minor allele frequency below our threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset SNP-matrix for phenotyped genotypes\n",
    "G = geno_hdf['snps'][:, acn_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove SNPs with minor allele frequency below set threshold\n",
    "# count allele 1 and 0 for each SNP\n",
    "AC1 = G.sum(axis = 1)\n",
    "AC0 = G.shape[1] - AC1\n",
    "AC = np.vstack((AC0,AC1))\n",
    "# define the minor allele for each position\n",
    "MAC = np.min(AC, axis = 0)\n",
    "# calculate minor allele frequency\n",
    "MAF = MAC/G.shape[1]\n",
    "# select SNPs with MAF above threshold \n",
    "SNP_indices = np.where(MAF >= MAF_thrs)[0]\n",
    "SNPs_MAF = MAF[SNP_indices]\n",
    "G = G[SNP_indices, :]\n",
    "\n",
    "# transpose SNP-matrix into accessions x SNPs matrix\n",
    "G = G.transpose()\n",
    "geno_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genotype matrix (G) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d.  Load kinship data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kin_hdf = h5py.File(kin_file, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2e. Finish kinship matrix (K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset kinship matrix for phenotyped and genotyped accessions\n",
    "acn_indices = [np.where(kin_hdf['accessions'][:] == acn)[0][0] for acn in pheno.index]\n",
    "acn_indices.sort()\n",
    "K = kin_hdf['kinship'][acn_indices, :][:, acn_indices]\n",
    "kin_hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 170)\n",
      "(170, 125066)\n",
      "(170, 1)\n"
     ]
    }
   ],
   "source": [
    "print(K.shape)\n",
    "print(G.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Running GWAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just quickly make sure our input matrices are the expected sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 170)\n",
      "(170, 125066)\n",
      "(170, 1)\n"
     ]
    }
   ],
   "source": [
    "print(K.shape)\n",
    "print(G.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have genotype (G), phenotype (Y), and K (K) matrices, we can run GWAS using the scan function from limix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><b><span style='color:#0C68C7'>============================= QTL analysis session starts ==============================</span></b></pre>"
      ],
      "text/plain": [
       "\u001b[1m\u001b[34m============================= QTL analysis session starts ==============================\u001b[m\u001b[m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising input... \n",
      "\u001b[1A\u001b[21Cdone (1.12 second).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LMM: 55it [00:00, 2481.49it/s]\n",
      "Scanning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 74.87it/s]\n",
      "Results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125066/125066 [00:08<00:00, 15078.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis 0\n",
      "============\n",
      "\n",
      "ð² ~ ð“(ð™¼ðœ¶, 422.851â‹…ð™º + 0.000â‹…ð™¸)\n",
      "\n",
      "M     = ['offset']\n",
      "ðœ¶     = [86.3851492]\n",
      "se(ðœ¶) = [51.39663417]\n",
      "lml   = -740.1760193587634\n",
      "\n",
      "Hypothesis 2\n",
      "============\n",
      "\n",
      "ð² ~ ð“(ð™¼ðœ¶ + Gð›ƒ, s(422.851â‹…ð™º + 0.000â‹…ð™¸))\n",
      "\n",
      "          lml       cov. effsizes   cand. effsizes\n",
      "--------------------------------------------------\n",
      "mean   -7.397e+02       8.611e+01        5.201e-01\n",
      "std     7.455e-01       1.722e+00        4.118e+00\n",
      "min    -7.402e+02       6.975e+01       -2.084e+01\n",
      "25%    -7.401e+02       8.547e+01       -2.129e+00\n",
      "50%    -7.399e+02       8.630e+01        4.310e-01\n",
      "75%    -7.395e+02       8.687e+01        3.080e+00\n",
      "max    -7.275e+02       1.001e+02        3.051e+01\n",
      "\n",
      "Likelihood-ratio test p-values\n",
      "==============================\n",
      "\n",
      "       ð“—â‚€ vs ð“—â‚‚ \n",
      "----------------\n",
      "mean   4.976e-01\n",
      "std    2.907e-01\n",
      "min    4.893e-07\n",
      "25%    2.454e-01\n",
      "50%    4.965e-01\n",
      "75%    7.491e-01\n",
      "max    1.000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielefiliault/opt/anaconda3/envs/limix/lib/python3.7/site-packages/limix/qtl/_result/_st_result.py:115: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  v0 = self.h0.variances[\"fore_covariance\"].item()\n",
      "/Users/danielefiliault/opt/anaconda3/envs/limix/lib/python3.7/site-packages/limix/qtl/_result/_st_result.py:116: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  v1 = self.h0.variances[\"back_covariance\"].item()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><b><span style='color:#0C68C7'>====================== QTL analysis session ends in 12.98 seconds ======================</span></b></pre>"
      ],
      "text/plain": [
       "\u001b[1m\u001b[34m====================== QTL analysis session ends in 12.98 seconds ======================\u001b[m\u001b[m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = scan(G, Y, K = K, lik = 'normal', M = None, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "# link chromosome and position to p-values and effect sizes\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "chr_index = geno_hdf['positions'].attrs['chr_regions']\n",
    "chromosomes = [bisect(chr_index[:, 1], snp_index) + 1 for snp_index in SNP_indices]\n",
    "positions_all = geno_hdf['positions'][:]\n",
    "positions = [positions_all[snp] for snp in SNP_indices]\n",
    "\n",
    "pvalues = r.stats.pv20.tolist()\n",
    "effsizes = r.effsizes['h2']['effsize'][r.effsizes['h2']['effect_type'] == 'candidate'].tolist()\n",
    "\n",
    "gwas_results = pd.DataFrame(list(zip(chromosomes, positions, pvalues, SNPs_MAF, MAC[SNP_indices], effsizes)), columns = ['chr', 'pos', 'pvalue', 'maf', 'mac', 'GVE'])\n",
    "gwas_results.to_csv(output_file, index = False)\n",
    "geno_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves the GWAS results as a .csv file that gives chromosome (chr), position (pos), p-value (pvalue), minor allele frequency (maf), minor allele count (mac), and effect size (GVE) for each SNP.  We will explore this output in the next jupyter notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
