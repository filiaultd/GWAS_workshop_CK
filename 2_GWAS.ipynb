{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GWAS using limix\n",
    "## Using our phenotype from the first notebook, we are going to run GWAS.\n",
    "\n",
    "### Steps of this notebook:\n",
    "Preparing input data  \n",
    "Running GWAS using the limix library for python  \n",
    "Outputting the results.\n",
    "\n",
    "Limix is freely available [here](https://github.com/limix/limix) and has an extensive [documentation](https://limix.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Initial setup steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from limix.qtl import scan\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phenotype file\n",
    "#pheno_file = './data/subset_flowering_time_16.csv'\n",
    "pheno_file = './data/subset_flowering_time_16.csv'\n",
    "\n",
    "# genotype file\n",
    "geno_file = './data/subset_all_chromosomes_binary.hdf5'\n",
    "\n",
    "# kinship matrix file\n",
    "kin_file = './data/kinship_ibs_binary_mac5.h5py'\n",
    "\n",
    "# minor allele frequency threshold - we will talk more about why we do this in the next notebook!\n",
    "# 10% is the standard cutoff we apply to *Arabidopsis thaliana* GWAS, but this may be different in your organism of choice.\n",
    "MAF_thrs = 0.1\n",
    "\n",
    "# output file for results with K correction\n",
    "output_file = './results/subset_flowering_time_16_gwas.csv'\n",
    "\n",
    "# output file for results without K correction\n",
    "output_file_nc = './results/subset_flowering_time_16_gwas_nc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load input for GWAS\n",
    "\n",
    "As a reminder, the linear mixed model for GWAS is:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "Y   = X\\beta + K + \\epsilon\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "We need three variables to run GWAS in limix:\n",
    "1.  Y = Phenotype matrix (Y in model)\n",
    "2.  G = Genotype matrix (X in model)\n",
    "3.  K = K matrix (K in model)\n",
    "\n",
    "limix will use this input to estimate the association p-value and effect size\n",
    "($\n",
    "\\begin{align}\n",
    "\\beta\n",
    "\\end{align}\n",
    "$) for each SNP.\n",
    "\n",
    "\n",
    "\n",
    "The first step to generating these three variables is to load the data.\n",
    "### Please Note!\n",
    "This script is written to handle data from the *Arabidopsis thaliana* 1001 genome project.  If you are running GWAS using another organism, you will more than likely start with data that is formatted differently!  If this is the case, some parts of this code *will not* work for you out of the box.  However, if you understand the __steps__ that this code takes, you will be able to adapt it to suit your specific input data.\n",
    "\n",
    "Therefore, I would like you to __focus on the general approach__ to generating the Y, G, and K matrices rather than trying to understand every line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Load phenotypes\n",
    "The phenotype data are stored in a 2-column .csv file.\n",
    "The first column specifies the accession identifier (\"ecotypeid\"), the second column contains the phenotype value.  Our flowering time dataset has 200 accessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenotype data\n",
    "pheno = pd.read_csv(pheno_file, index_col = 0)\n",
    "\n",
    "# encode the index (the accessions column) to UTF8 so it matches encoding of accessions in the genotype data.\n",
    "# this will allow us to compare the two datasets in section 3a. \n",
    "pheno.index = pheno.index.map(lambda x: str(int(x)).encode('UTF8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove accessions with missing or non numerical data\n",
    "pheno = pheno.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "           flowering_time_16\n",
      "ecotypeid                   \n",
      "b'770'                 72.25\n",
      "b'801'                 88.25\n",
      "b'991'                106.75\n",
      "b'1062'                68.25\n",
      "b'1367'                88.75\n"
     ]
    }
   ],
   "source": [
    "# does pheno match our expectations?\n",
    "print(pheno.shape)\n",
    "print(pheno.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenotypes are loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Load genotypes\n",
    "The genotypes we're going to use are a subset of SNPs obtained from whole-genome resequencing of 1,135 *Arabidopsis thaliana* accessions ([1001 genomes](http://1001genomes.org/)).\n",
    "\n",
    "Genotype data is stored as an [hdf5](https://www.h5py.org/) file, which is a composite data type.  This means that one hdf5 file stores multiple related data sets. \n",
    "\n",
    "The genotype hdf5 file we are using here consists of three data sets:\n",
    "1.  'accessions' contains the accession identifiers.\n",
    "2.  'positions' provides the SNP positions.\n",
    "3.  'snps' gives the SNP calls themselves. SNPs are coded as 0 for reference allele and 1 for alternate allele.\n",
    "\n",
    "The 'positions' dataset is also associated with a small file called an attribute which provides information about the chromosome location ('chr_index').  We will use the attribute later when outputting GWAS results.\n",
    "\n",
    "(If you are interested in learning more about how to use hdf5 files, check out https://www.pythonforthelab.com/blog/how-to-use-hdf5-files-in-python/ after class for a more detailed introduction.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accessions\n",
      "(1135,)\n",
      "[b'88' b'108' b'139' b'159' b'265' b'350' b'351' b'403' b'410' b'424']\n",
      "positions\n",
      "(1070995,)\n",
      "[ 55 101 139 203 237 291 332 375 431 502]\n",
      "snps\n",
      "(1070995, 1135)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# load genotype data\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "# structure of hdf5 file\n",
    "# does geno_hdf match our expectations? Here, \"key\" refers to the three different data sets\n",
    "for key in geno_hdf.keys():\n",
    "    print(key)\n",
    "    print(geno_hdf[key].shape)\n",
    "    print(geno_hdf[key][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c.  Load K matrix\n",
    "The kinship matrix we are using is an IBS (identity by state) matrix calculated with the complete SNP dataset (rather than the SNP subset we are using).  As discussed in lecture, there any many options for calculating a K matrix, but we are using a pre-calculated matrix to save ourselves the long computation time.\n",
    "\n",
    "The input file is also an hdf5 file.  It contains 2 datasets:\n",
    "1. 'accessions' gives the accession identifiers\n",
    "2. 'kinship' is the kinship matrix.  (In this case, it is calculated for all 1135 accessions in the complete 1001 genomes dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1135,)\n",
      "[b'88' b'108' b'139' b'159' b'265']\n",
      "(1135, 1135)\n",
      "[[7.32260312 6.44804411 6.44906758 ... 6.33012188 6.33045141 6.33019166]\n",
      " [6.44804411 7.32260312 7.30934451 ... 6.32966248 6.3303099  6.33010831]\n",
      " [6.44906758 7.30934451 7.32260312 ... 6.33023237 6.33063943 6.33054639]\n",
      " [6.44129268 6.38031273 6.37999871 ... 6.34332622 6.34272144 6.34269043]\n",
      " [6.33677639 6.34437683 6.34471411 ... 6.2482848  6.24887795 6.24868411]]\n"
     ]
    }
   ],
   "source": [
    "kin_hdf = h5py.File(kin_file, 'r')\n",
    "\n",
    "print(kin_hdf['accessions'].shape)\n",
    "print(kin_hdf['accessions'][0:5])\n",
    "print(kin_hdf['kinship'].shape)\n",
    "print(kin_hdf['kinship'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Generating matrices for GWAS\n",
    "Now that the data have been loaded, we need to do some final manipulations to generate the appropriate input matrices.\n",
    "\n",
    "We have __*three main objectives*__ here:\n",
    "\n",
    "1.  Since limix will not work with missing data, we need to make sure that all three matrices include the __same set of accessions__.\n",
    "2.  We also need to make sure that the accessions appear in the __same order__ in all three matrices.\n",
    "3.  We will also remove any SNPs that don't meet our __minor allele frequency__ threshold. (We will return to the reason for this step in the next notebook.)\n",
    "\n",
    "Again, this code will work for the 1001 genomes data out of the box, but will likely need to be modified for other data.  Therefore, focus on the __steps__ rather than on each individual line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a.  Generate phenotype matrix (Y)\n",
    "\n",
    "We now have the phenotypes stored as the variable called 'pheno'.  To make the phenotype matrix (Y), we need to __*remove non-genotyped accessions*__ and __*order the data*__ to match the genotype data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-genotyped accessions from phenotype\n",
    "acn_genotyped = [acn for acn in pheno.index if acn in geno_hdf['accessions'][:]]\n",
    "# subset phenotype data\n",
    "pheno = pheno.loc[acn_genotyped]\n",
    "# order genotypes in phenotype according SNP-matrix\n",
    "acn_indices = [np.where(geno_hdf['accessions'][:] == acn)[0][0] for acn in pheno.index]\n",
    "acn_indices.sort()\n",
    "acn_order = geno_hdf['accessions'][acn_indices]\n",
    "pheno = pheno.loc[acn_order]\n",
    "# transform to a numpy phenotype matrix (Y)\n",
    "Y = pheno.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenotype matrix (Y) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Generate genotype matrix (G)\n",
    "Now we can finish the genotype matrix (G).  Here we remove:\n",
    "1. accessions that are not phenotyped \n",
    "2. SNPs with a minor allele frequency below our threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset SNP matrix for phenotyped genotypes\n",
    "# be patient - this step can take a few minutes\n",
    "G = geno_hdf['snps'][:, acn_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove SNPs with minor allele frequency below set threshold\n",
    "# count allele 1 and 0 for each SNP\n",
    "AC1 = G.sum(axis = 1)\n",
    "AC0 = G.shape[1] - AC1\n",
    "AC = np.vstack((AC0,AC1))\n",
    "# define the minor allele for each position\n",
    "MAC = np.min(AC, axis = 0)\n",
    "# calculate minor allele frequency\n",
    "MAF = MAC/G.shape[1]\n",
    "# select SNPs with MAF above threshold \n",
    "SNP_indices = np.where(MAF >= MAF_thrs)[0]\n",
    "SNPs_MAF = MAF[SNP_indices]\n",
    "G = G[SNP_indices, :]\n",
    "\n",
    "# transpose SNP-matrix into accessions x SNPs matrix\n",
    "G = G.transpose()\n",
    "geno_hdf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The genotype matrix (G) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Generate kinship matrix (K)\n",
    "To finish the kinship array, subset for accessions that are phenotyped and genotyped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset kinship matrix for phenotyped and genotyped accessions\n",
    "acn_indices = [np.where(kin_hdf['accessions'][:] == acn)[0][0] for acn in pheno.index]\n",
    "acn_indices.sort()\n",
    "K = kin_hdf['kinship'][acn_indices, :][:, acn_indices]\n",
    "kin_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kinship matrix (K) is now ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Check input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all three of our input variables.  If you are running GWAS using something other than the 1001 genomes data, __*these are the matrices that you need to generate to run limix*__.  Let's quickly look at these variables to make sure we understand their format.  The number of accessions should be the same in all three matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Y matrix (phenotypes)\n",
    "*Y is a numpy array.\n",
    "The number of rows = number of accessions.\n",
    "The number of columns = 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(170, 1)\n",
      "[[ 88.25      ]\n",
      " [106.75      ]\n",
      " [ 68.25      ]\n",
      " [ 69.33333333]\n",
      " [ 69.75      ]]\n"
     ]
    }
   ],
   "source": [
    "print(type(Y))\n",
    "print(Y.shape)\n",
    "print(Y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. G matrix (genotypes)\n",
    "*G is a numpy array.  The number of rows = number of accessions.  The number of columns = the number of snps.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(170, 125066)\n",
      "[[0 0 0 ... 0 1 1]\n",
      " [1 1 1 ... 0 0 1]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(type(G))\n",
    "print(G.shape)\n",
    "print(G[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. K matrix (K matrix)\n",
    "*K is a numpy array.  The number of rows and columns = the number of accessions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(170, 170)\n",
      "[[7.32260312 6.34682696 6.33634413 ... 6.34759263 6.32583997 6.35192106]\n",
      " [6.34682696 7.32260312 6.42985228 ... 6.3919586  6.2824742  6.35606923]\n",
      " [6.33634413 6.42985228 7.32260312 ... 6.36691067 6.29265853 6.33635963]\n",
      " ...\n",
      " [6.34759263 6.3919586  6.36691067 ... 7.32260312 6.31910792 6.37552489]\n",
      " [6.32583997 6.2824742  6.29265853 ... 6.31910792 7.32260312 6.32155224]\n",
      " [6.35192106 6.35606923 6.33635963 ... 6.37552489 6.32155224 7.32260312]]\n"
     ]
    }
   ],
   "source": [
    "print(type(K))\n",
    "print(K.shape)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  Run GWAS\n",
    "We are going to run two GWAS with our phenotype of interest.  The first one will include a population structure correction (i.e. the model will include the K matrix) and the second one will not (we will compare the results in the next notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a.  Run limix with K correction\n",
    "\n",
    "Now that we have phenotype (Y), genotype (G), and K (K) matrices, we can run GWAS using the 'scan' function from limix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><b><span style='color:#0C68C7'>============================= QTL analysis session starts ==============================</span></b></pre>"
      ],
      "text/plain": [
       "\u001b[1m\u001b[34m============================= QTL analysis session starts ==============================\u001b[m\u001b[m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising input... \n",
      "\u001b[1A\u001b[21Cdone (1.13 second).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LMM: 55it [00:00, 3846.64it/s]\n",
      "Scanning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 163.37it/s]\n",
      "Results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125066/125066 [00:03<00:00, 36846.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis 0\n",
      "============\n",
      "\n",
      "ð² ~ ð“(ð™¼ðœ¶, 422.851â‹…ð™º + 0.000â‹…ð™¸)\n",
      "\n",
      "M     = ['offset']\n",
      "ðœ¶     = [86.3851492]\n",
      "se(ðœ¶) = [51.39663417]\n",
      "lml   = -740.1760193587634\n",
      "\n",
      "Hypothesis 2\n",
      "============\n",
      "\n",
      "ð² ~ ð“(ð™¼ðœ¶ + Gð›ƒ, s(422.851â‹…ð™º + 0.000â‹…ð™¸))\n",
      "\n",
      "          lml       cov. effsizes   cand. effsizes\n",
      "--------------------------------------------------\n",
      "mean   -7.397e+02       8.611e+01        5.201e-01\n",
      "std     7.455e-01       1.722e+00        4.118e+00\n",
      "min    -7.402e+02       6.975e+01       -2.084e+01\n",
      "25%    -7.401e+02       8.547e+01       -2.129e+00\n",
      "50%    -7.399e+02       8.630e+01        4.310e-01\n",
      "75%    -7.395e+02       8.687e+01        3.080e+00\n",
      "max    -7.275e+02       1.001e+02        3.051e+01\n",
      "\n",
      "Likelihood-ratio test p-values\n",
      "==============================\n",
      "\n",
      "       ð“—â‚€ vs ð“—â‚‚ \n",
      "----------------\n",
      "mean   4.976e-01\n",
      "std    2.907e-01\n",
      "min    4.893e-07\n",
      "25%    2.454e-01\n",
      "50%    4.965e-01\n",
      "75%    7.491e-01\n",
      "max    1.000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielefiliault/opt/anaconda3/envs/limix/lib/python3.7/site-packages/limix/qtl/_result/_st_result.py:115: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  v0 = self.h0.variances[\"fore_covariance\"].item()\n",
      "/Users/danielefiliault/opt/anaconda3/envs/limix/lib/python3.7/site-packages/limix/qtl/_result/_st_result.py:116: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  v1 = self.h0.variances[\"back_covariance\"].item()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><b><span style='color:#0C68C7'>====================== QTL analysis session ends in 6.62 seconds =======================</span></b></pre>"
      ],
      "text/plain": [
       "\u001b[1m\u001b[34m====================== QTL analysis session ends in 6.62 seconds =======================\u001b[m\u001b[m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = scan(G, Y, K = K, lik = 'normal', M = None, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the output generated by limix.  Limix has run the linear mixed model for each SNP, and this output summarizes the range of values calculated across all these tests.\n",
    "Although this output is quite detailed, we are primarily interested in two values from limix:\n",
    "\n",
    "1. __P-value__ - This is the p-value for the test that a SNP is associated with the phenotype.  Limix calculates this as likelihood-ratio test between our full GWAS model (H2 in the output) and a model that doesn't contain the genotype term (H0 in the output).  The range of these values across all tested SNPs is given under the heading \"Likelihood-ratio test p-values\".\n",
    "2. __Effect size__ - This is the effect of a SNP in the linear model (the beta in the GWAS equation).   The range of these values across all tested SNPs is given as \"cand. effsizes\" in the table below \"Hypothesis 2\".\n",
    "\n",
    "In the next section, we will output the p-values and effect sizes for all SNPs tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b.  Output results for limix with K correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at the results of these GWAS is the next notebook.  This cell saves the GWAS results as a .csv file that gives chromosome (chr), position (pos), p-value (pvalue), minor allele frequency (maf), and effect size (GVE) for each SNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "# get chromosomes, positions, and minor allele frequencies\n",
    "# you would need to recode this section if working with something other than the 1001 genomes data\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "chr_index = geno_hdf['positions'].attrs['chr_regions']\n",
    "chromosomes = [bisect(chr_index[:, 1], snp_index) + 1 for snp_index in SNP_indices]\n",
    "positions_all = geno_hdf['positions'][:]\n",
    "positions = [positions_all[snp] for snp in SNP_indices]\n",
    "mafs = SNPs_MAF #from section 3b\n",
    "\n",
    "# get p-value and effect size\n",
    "# these variables are output from limix and should work regardless of initial input data format\n",
    "#extract p-values\n",
    "pvalues = r.stats.pv20.tolist()\n",
    "#extract effect sizes\n",
    "effsizes = r.effsizes['h2']['effsize'][r.effsizes['h2']['effect_type'] == 'candidate'].tolist()\n",
    "\n",
    "gwas_results = pd.DataFrame(list(zip(chromosomes, positions, pvalues, mafs, effsizes)), columns = ['chr', 'pos', 'pvalue', 'maf', 'GVE'])\n",
    "gwas_results.to_csv(output_file, index = False)\n",
    "geno_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c.  Run limix without K correction\n",
    "\n",
    "We will also run limix without population structure correction (i.e. without K in the model) so we can compare results in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre><b><span style='color:#0C68C7'>============================= QTL analysis session starts ==============================</span></b></pre>"
      ],
      "text/plain": [
       "\u001b[1m\u001b[34m============================= QTL analysis session starts ==============================\u001b[m\u001b[m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising input... \n",
      "\u001b[1A\u001b[21Cdone (0.53 seconds).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 173.79it/s]\n",
      "Results: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125066/125066 [00:03<00:00, 38026.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothesis 0\n",
      "============\n",
      "\n",
      "ð² ~ ð“(ð™¼ðœ¶, 653.950â‹…ð™¸)\n",
      "\n",
      "M     = ['offset']\n",
      "ðœ¶     = [76.3995098]\n",
      "se(ðœ¶) = [1.96131695]\n",
      "lml   = -792.277165089571\n",
      "\n",
      "Hypothesis 2\n",
      "============\n",
      "\n",
      "ð² ~ ð“(ð™¼ðœ¶ + Gð›ƒ, s(653.950â‹…ð™¸))\n",
      "\n",
      "          lml       cov. effsizes   cand. effsizes\n",
      "--------------------------------------------------\n",
      "mean   -7.902e+02       7.578e+01        1.860e+00\n",
      "std     2.961e+00       3.724e+00        9.727e+00\n",
      "min    -7.923e+02       4.870e+01       -3.737e+01\n",
      "25%    -7.921e+02       7.403e+01       -4.875e+00\n",
      "50%    -7.914e+02       7.608e+01        1.325e+00\n",
      "75%    -7.896e+02       7.756e+01        8.047e+00\n",
      "max    -7.629e+02       1.100e+02        4.610e+01\n",
      "\n",
      "Likelihood-ratio test p-values\n",
      "==============================\n",
      "\n",
      "       ð“—â‚€ vs ð“—â‚‚ \n",
      "----------------\n",
      "mean   2.955e-01\n",
      "std    3.058e-01\n",
      "min    1.721e-14\n",
      "25%    2.071e-02\n",
      "50%    1.785e-01\n",
      "75%    5.252e-01\n",
      "max    1.000e+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre><b><span style='color:#0C68C7'>====================== QTL analysis session ends in 5.56 seconds =======================</span></b></pre>"
      ],
      "text/plain": [
       "\u001b[1m\u001b[34m====================== QTL analysis session ends in 5.56 seconds =======================\u001b[m\u001b[m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_nc = scan(G, Y, lik=\"normal\", M=None, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output is in the same format as that of section 5a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5d.  Output results for limix without K correction\n",
    "We will look at the results of these GWAS is the next notebook.  This cell saves the GWAS results as a .csv file that gives chromosome (chr), position (pos), p-value (pvalue), minor allele frequency (maf), and effect size (GVE) for each SNP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "# link chromosome and position to p-values and effect sizes\n",
    "geno_hdf = h5py.File(geno_file, 'r')\n",
    "chr_index = geno_hdf['positions'].attrs['chr_regions']\n",
    "chromosomes = [bisect(chr_index[:, 1], snp_index) + 1 for snp_index in SNP_indices]\n",
    "positions_all = geno_hdf['positions'][:]\n",
    "positions = [positions_all[snp] for snp in SNP_indices]\n",
    "mafs = SNPs_MAF #from section 3b\n",
    "\n",
    "pvalues = r_nc.stats.pv20.tolist()\n",
    "effsizes = r_nc.effsizes['h2']['effsize'][r_nc.effsizes['h2']['effect_type'] == 'candidate'].tolist()\n",
    "\n",
    "gwas_results = pd.DataFrame(list(zip(chromosomes, positions, pvalues, mafs, effsizes)), columns = ['chr', 'pos', 'pvalue', 'maf', 'GVE'])\n",
    "gwas_results.to_csv(output_file_nc, index = False)\n",
    "geno_hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### In this notebook, we have learned about input data, run GWAS, and output GWAS results.\n",
    " ### Let's move on to 3_GWAS_interpretation.ipynb, where we will explore these results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
